# NeuralScribe

**Real-time handwritten character recognition with live neural network visualization.**

[![Python 3.10+](https://img.shields.io/badge/Python-3.10+-3776ab?style=flat-square&logo=python&logoColor=white)](https://python.org)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-ee4c2c?style=flat-square&logo=pytorch&logoColor=white)](https://pytorch.org)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.104+-009688?style=flat-square&logo=fastapi&logoColor=white)](https://fastapi.tiangolo.com)
[![License: MIT](https://img.shields.io/badge/License-MIT-22d3ee?style=flat-square)](LICENSE)

<!-- 
ğŸ“¸ HERO IMAGE â€” This is the most important visual. Take a screenshot showing:
   - Dark theme active
   - A character drawn on the canvas (try "R" or "7" â€” something with clear network activation)
   - The network visualization lighting up with green predicted path
   - Confidence bars showing the prediction
   - Accuracy chart with training data visible
   
   Save as: assets/hero.png (recommended: 1920Ã—1080 or wider)
   Tip: Use browser DevTools â†’ Ctrl+Shift+P â†’ "Capture full size screenshot" for clean capture
-->
![NeuralScribe Dashboard](assets/hero.png)

---

## What is this?

NeuralScribe is an interactive dashboard for training and running a CNN on the EMNIST dataset â€” 47 classes covering digits (0â€“9), uppercase letters (Aâ€“Z), and 11 lowercase letters. Draw a character, watch the neural network think in real time.

<!-- 
ğŸ¬ DEMO GIF â€” Record a ~10 second GIF showing:
   1. Drawing a character on the canvas
   2. The prediction updating LIVE as you draw (the confidence bars moving)
   3. The neural network visualization lighting up
   
   How to record:
   - Windows: ShareX (free) â†’ Screen Recording â†’ GIF
   - Mac: Gifox or Kap
   - Any OS: ScreenToGif (free)
   
   Settings: 720p, 15fps, crop to just the dashboard
   Save as: assets/demo.gif
-->
![Live Demo](assets/demo.gif)

### Why it's interesting

| Feature | What happens |
|---------|-------------|
| **Live inference** | Predictions update mid-stroke via WebSocket â€” no submit button |
| **Neural network visualization** | Watch 6 CNN layers activate. Green = predicted path, red = competing signals |
| **Both themes** | Dark (research lab) and light (clean paper) â€” one click toggle |
| **Train from the UI** | Hit Train, set epochs (up to 100), watch accuracy climb in real time |
| **Full probability view** | See confidence across all 47 classes â€” digits in cyan, letters in violet |

---

## Quick Start

```bash
# Clone
git clone https://github.com/yourusername/neuralscribe.git
cd neuralscribe

# Environment
python -m venv .venv
.venv\Scripts\activate
python.exe -m pip install --upgrade pip

# Dependencies
pip install -r requirements.txt

# GPU support (CUDA 12.8)
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu128

# Launch
python run_backend.py
```

Open **http://localhost:8000** â†’ Click **Train** â†’ Set 35 epochs â†’ Start â†’ Draw.

---

## Screenshots

<!-- 
ğŸ“¸ DARK THEME SCREENSHOT â€” Full dashboard, dark theme, with a prediction active
   Save as: assets/dark-theme.png
-->
### Dark Theme
![Dark Theme](assets/dark-theme.png)

<!-- 
ğŸ“¸ LIGHT THEME SCREENSHOT â€” Same state but light theme toggled
   Save as: assets/light-theme.png
-->
### Light Theme
![Light Theme](assets/light-theme.png)

<!-- 
ğŸ“¸ TRAINING SCREENSHOT â€” Capture while training is in progress showing:
   - Progress bar with ETA
   - Accuracy chart building up
   - Loss chart decreasing
   - Status pill showing "TRAINING"
   Save as: assets/training.png
-->
### Live Training
![Training](assets/training.png)

<!-- 
ğŸ¬ NETWORK VIZ GIF â€” Record a ~5 second GIF showing:
   - Draw one character, then clear, draw another
   - Focus on the neural network panel â€” the connections shifting between predictions
   - Crop to just the network visualization panel
   Save as: assets/network-viz.gif
-->
### Neural Network Visualization
![Network Visualization](assets/network-viz.gif)

The visualization shows 6 layers of the CNN in real time:

```
Input â†’ Conv1 â†’ Conv2 â†’ Dense1 â†’ Dense2 â†’ Output (47 classes)
```

- **Green connections** â€” the predicted path (strongest signal to the winning class)
- **Red connections** â€” competing activations (what the network considered but rejected)  
- **Node brightness** â€” activation strength at each neuron
- **Output labels** â€” top predicted classes with confidence percentages

---

## Architecture

### Frontend (Modular ES Modules)

```
frontend/
â”œâ”€â”€ index.html              # Page structure
â”œâ”€â”€ style.css               # Design system (dark + light themes)
â”œâ”€â”€ main.js                 # Entry point â€” WebSocket, DOM bindings
â”œâ”€â”€ state/
â”‚   â””â”€â”€ appState.js         # Reactive state store (pub/sub)
â””â”€â”€ ui/
    â”œâ”€â”€ theme.js            # Dark/light toggle
    â”œâ”€â”€ canvas.js           # Drawing, undo, pixel extraction
    â”œâ”€â”€ networkViz.js       # 6-layer CNN visualization
    â””â”€â”€ charts.js           # Accuracy + Loss charts
```

**State flows one direction:**

```
User action â†’ module â†’ appState.update() â†’ subscribers re-render
```

No module touches another module's DOM. Everything goes through state.

### Backend (PyTorch + FastAPI)

```
backend/
â”œâ”€â”€ api/
â”‚   â””â”€â”€ app.py              # FastAPI server + WebSocket
â”œâ”€â”€ interface/
â”‚   â”œâ”€â”€ preprocess.py       # Canvas â†’ EMNIST tensor pipeline
â”‚   â””â”€â”€ predictor.py        # Inference engine with TTA
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ model.py            # CNN architecture (ResBlocks + SE attention)
â”‚   â”œâ”€â”€ dataset.py          # EMNIST data loader with augmentation
â”‚   â””â”€â”€ train.py            # Training loop (mixed precision, warm restarts)
â””â”€â”€ models/
    â””â”€â”€ digit_model.pt      # Trained weights (generated after training)
```

### Model

| Property | Value |
|----------|-------|
| Architecture | Stem â†’ 4Ã— ResBlock (with SE attention) â†’ GAP â†’ FC |
| Parameters | ~650K |
| Input | 28Ã—28 grayscale |
| Output | 47 classes (EMNIST ByMerge) |
| Training | AdamW, CosineAnnealingWarmRestarts, Focal Loss, Mixup |
| Inference | Test-Time Augmentation (5 variants averaged) |

### Communication

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    WebSocket     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Frontend â”‚ â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º â”‚ Backend  â”‚
â”‚          â”‚   JSON messages   â”‚ FastAPI  â”‚
â”‚ canvas â†’ â”‚ â”€â”€ predict â”€â”€â”€â”€â”€â–º â”‚ â†’ model  â”‚
â”‚ â† bars   â”‚ â—„â”€ prediction â”€â”€ â”‚ â† output â”‚
â”‚ â† chart  â”‚ â—„â”€ train_update â”€â”‚ (async)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

Real-time via WebSocket. REST fallback at `/api/predict` and `/api/status`.

---

## Training Details

### Recommended Settings

| Setting | Value | Why |
|---------|-------|-----|
| Epochs | 30â€“50 | Warm restarts need multiple LR cycles |
| Default LR | 0.003 | BatchNorm allows higher rates |
| Batch size | 128 | GPU utilization vs generalization balance |

### Accuracy Improvements

The model includes 8 techniques stacked for maximum accuracy:

1. **Data augmentation** â€” rotation, translation, perspective, blur, erasing
2. **Preprocessing alignment** â€” center-of-mass centering + EMNIST transpose
3. **Warm restarts** â€” CosineAnnealingWarmRestarts escapes local minima
4. **Test-time augmentation** â€” 5 inference variants averaged
5. **Model capacity** â€” wider channels (64â†’160â†’320â†’256) with stochastic depth
6. **Mixup regularization** â€” blends training pairs for smoother boundaries
7. **Focal loss** â€” focuses learning on hard/confusable characters
8. **SE attention blocks** â€” learns which feature channels matter most

Expected accuracy: **95â€“97%+** on EMNIST ByMerge (SOTA baseline is ~91â€“92%).

<!-- 
ğŸ“¸ ACCURACY CHART SCREENSHOT â€” After training completes, capture:
   - The accuracy chart showing the full training curve
   - Final accuracy visible in the stats panel
   Save as: assets/accuracy.png
-->
![Training Accuracy](assets/accuracy.png)

---

## Design

### Typography
- **Syne** â€” geometric display font for the brand name "Neural"
- **Caveat** â€” handwriting font for "Scribe" â€” the neural + handwriting theme
- **Outfit** â€” clean body text
- **Geist Mono** â€” monospaced data, stats, labels

### Color System

| Token | Dark | Light | Used for |
|-------|------|-------|----------|
| `--accent` | `#22d3ee` | `#0891b2` | Primary accent, canvas border, predictions |
| `--green` | `#34d399` | `#059669` | Network viz, accuracy, success states |
| `--amber` | `#fbbf24` | `#d97706` | Loss charts, warning states |
| `--violet` | `#a78bfa` | `#7c3aed` | Letter confidence bars, progress gradient |
| `--red` | `#f87171` | `#dc2626` | Danger actions, competing network paths |

### Performance

- **Wireframe caching** â€” static network connections drawn once, stored as ImageData
- **requestAnimationFrame gating** â€” no redundant draws
- **Pixel queue** â€” predictions fire continuously while drawing, never blocked by pending responses
- **Throttled canvas reads** â€” 50ms minimum between pixel extractions

---

## Configuration

### Environment

| Variable | Default | Description |
|----------|---------|-------------|
| GPU | Auto-detected | Uses CUDA if available, falls back to CPU |
| Port | 8000 | Set in `run_backend.py` |
| Model path | `backend/models/digit_model.pt` | Auto-created on first training |
| Data path | `data/raw/emnist/` | EMNIST auto-downloads (~500 MB) |

### Training from CLI

```bash
# Train directly without the UI
python -m backend.train.train --epochs 50
```

---

## Troubleshooting

| Problem | Fix |
|---------|-----|
| "No Model" after launch | Click Train â†’ set epochs â†’ Start |
| CUDA out of memory | Reduce batch size in `train.py` or use CPU |
| Slow inference (~400ms) | Disable TTA in `predictor.py` (`use_tta=False`) for ~5x speedup |
| Wrong predictions | Delete `backend/models/digit_model.pt` and retrain with 35+ epochs |
| WebSocket disconnects | Check firewall, ensure port 8000 is open |
| Workers crash on Windows | `dataset.py` handles this â€” uses `persistent_workers=False` on Windows |

---

## Tech Stack

- **Runtime**: Python 3.10+
- **ML**: PyTorch 2.0+ (mixed precision, AMP)
- **Server**: FastAPI + Uvicorn (WebSocket + REST)
- **Frontend**: Vanilla ES Modules (zero dependencies, no build step)
- **Fonts**: Google Fonts (Syne, Caveat, Outfit, Geist Mono)

---

## License

MIT

---

<p align="center">
  <b>Neural</b><i>Scribe</i> â€” watch a neural network learn to read your handwriting.
</p>